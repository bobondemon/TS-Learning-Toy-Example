{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classifier Experiments with MNIST\n",
    "A typical CNN classifier for MNIST. Could makes 99% in both train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "# from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Shuffle arrays or sparse matrices in a consistent way\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dataset/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "dataPath='../dataset/MNIST_data/'\n",
    "mnist = input_data.read_data_sets(dataPath, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the images and reformat the image shape from [img_num,img_height,img_width] to [img_num,img_height,img_width,1]\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "images = mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having 5417 and 5454 for 6 and 9 respectively\n"
     ]
    }
   ],
   "source": [
    "# read the labels, 6 --> class 0; 9 --> class 1\n",
    "y1hot_all = mnist.train.labels\n",
    "y_all = np.argmax(y1hot_all,axis=1)\n",
    "idx6 = np.nonzero(y_all==6)[0]\n",
    "idx9 = np.nonzero(y_all==9)[0]\n",
    "idx69 = np.concatenate([idx6, idx9])\n",
    "print('Having {} and {} for 6 and 9 respectively'.format(len(idx6),len(idx9)))\n",
    "y = np.copy(y_all)\n",
    "y[idx6] = 0\n",
    "y[idx9] = 1\n",
    "y = y[idx69]\n",
    "y = y[...,np.newaxis]\n",
    "y1hot = [[int(x[6]), int(x[9])] for x in y1hot_all[idx69]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allidx = set(range(len(y_all)))\n",
    "restidx = list(set.difference(allidx,set(idx69)))\n",
    "#print(len(restidx),len(idx69),len(allidx))\n",
    "#assert(len(restidx)+len(idx69)==len(allidx))\n",
    "y1hot_rest_flip = [[1, 0] for x in y1hot_all[restidx]]\n",
    "#print(len(y1hot_rest_flip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input to CNN) Images with shape (10871, 28, 28, 1)\n",
      "(Input to CNN) Rest of Images with shape (44129, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# read the images and reformat the image shape from [img_num,img_height,img_width] to [img_num,img_height,img_width,1]\n",
    "# extract 6, 9 as training images. The rest of images are for unsupervised training\n",
    "n_classes = 2\n",
    "x = images[idx69]\n",
    "x_num, _ = x.shape\n",
    "assert(len(x)==len(y))\n",
    "x = np.reshape(x,(x_num,img_height,img_width))\n",
    "x = x[...,np.newaxis]\n",
    "print('(Input to CNN) Images with shape {}'.format(x.shape))\n",
    "restidx = list( set.difference( set(range(len(images))), set(idx69) ) )\n",
    "assert(len(restidx)+len(x)==len(images))\n",
    "x_rest = images[restidx]\n",
    "x_rest_num, _ = x_rest.shape\n",
    "x_rest = np.reshape(x_rest,(x_rest_num,img_height,img_width))\n",
    "x_rest = x_rest[...,np.newaxis]\n",
    "print('(Input to CNN) Rest of Images with shape {}'.format(x_rest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAEpCAYAAADieNHgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Dv8glnYokwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b81d7a9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate testing input as flipping upside down images to training data\n",
    "y1hot_flip = np.copy(y1hot)\n",
    "y_flip = np.copy(y)\n",
    "def flip(img):\n",
    "    rtnimg = np.array([img[img_height-1-i,...] for i in range(img_height)])\n",
    "    return rtnimg\n",
    "x_flip = list(map(lambda img: flip(img),x))\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in np.arange(2*7):\n",
    "    plt.subplot(2,7,i+1)\n",
    "    plt.imshow(x_flip[5411+i][...,0],cmap='gray')\n",
    "    plt.title(y_flip[5411+i][0])\n",
    "    \n",
    "x_rest_flip = list(map(lambda img: flip(img),x_rest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN Graph Construction\n",
    "\n",
    "1. Define the input output tensors\n",
    "2. Define the graph and construct it\n",
    "3. Define the loss and optimizer\n",
    "\n",
    "### First define the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "EPOCHS = 3\n",
    "EPOCHS_TF = 10\n",
    "BATCH_SIZE = 128\n",
    "rate = 0.001\n",
    "drop_out_keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the input output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using one-hot decoding\n",
    "cNum = 1\n",
    "x_feed = tf.placeholder(tf.float32, (None, img_height, img_width, cNum))\n",
    "one_hot_y_feed = tf.placeholder(tf.int32, (None, n_classes))\n",
    "\n",
    "x_feed_student = tf.placeholder(tf.float32, (None, img_height, img_width, cNum))\n",
    "one_hot_y_feed_student = tf.placeholder(tf.int32, (None, n_classes))\n",
    "#one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the graph and construct it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kSize = 5\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "layer_depth = {\n",
    "    'layer_1': 16,\n",
    "    'layer_2': 32,\n",
    "    'fully_connected_1': 256,\n",
    "    'fully_connected_2': 128,\n",
    "    'out': n_classes,\n",
    "}\n",
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 has shape= (?, 24, 24, 16)\n",
      "conv2 has shape= (?, 8, 8, 32)\n",
      "flatten(conv2) has shape= (?, 512)\n",
      "logits has shape= (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# CNN architecture\n",
    "\n",
    "with tf.variable_scope('teacher'):\n",
    "    weights = {\n",
    "        'layer_1': tf.get_variable('layer_1w', shape=(kSize, kSize, cNum, layer_depth['layer_1']),initializer=tf.random_normal_initializer(mu,sigma)),\n",
    "        'layer_2': tf.get_variable('layer_2w', shape=(kSize, kSize, layer_depth['layer_1'], layer_depth['layer_2']),initializer=tf.random_normal_initializer(mu,sigma)),\n",
    "        'fully_connected_1': tf.get_variable('fully_connected_1w', shape=(4*4*layer_depth['layer_2'], layer_depth['fully_connected_1']),initializer=tf.random_normal_initializer(mu,sigma)),\n",
    "        'fully_connected_2': tf.get_variable('fully_connected_2w', shape=(layer_depth['fully_connected_1'], layer_depth['fully_connected_2']),initializer=tf.random_normal_initializer(mu,sigma)),\n",
    "        'out': tf.get_variable('outw', shape=(layer_depth['fully_connected_2'], layer_depth['out']),initializer=tf.random_normal_initializer(mu,sigma))\n",
    "    }\n",
    "    #+0.3 over the first epochs than +-0\n",
    "\n",
    "    biases = {\n",
    "        'layer_1': tf.get_variable('layer_1b', shape=(layer_depth['layer_1']),initializer=tf.zeros_initializer),\n",
    "        'layer_2': tf.get_variable('layer_2b', shape=(layer_depth['layer_2']),initializer=tf.zeros_initializer),\n",
    "        'fully_connected_1': tf.get_variable('fully_connected_1b', shape=(layer_depth['fully_connected_1']),initializer=tf.zeros_initializer),\n",
    "        'fully_connected_2': tf.get_variable('fully_connected_2b', shape=(layer_depth['fully_connected_2']),initializer=tf.zeros_initializer),\n",
    "        'out': tf.get_variable('outb', shape=(layer_depth['out']),initializer=tf.zeros_initializer)\n",
    "    }\n",
    "\n",
    "def CNNMNIST_teacher(x):\n",
    "    # Layer 1: Convolutional. Input = 28x28xcNum. Output = 24x24xlayer_depth['layer_1'].\n",
    "    conv1   = tf.nn.conv2d(x, weights['layer_1'], strides=[1, 1, 1, 1], padding='VALID') + biases['layer_1']\n",
    "    print('conv1 has shape=',conv1.shape)\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 24x24xlayer_depth['layer_1']. Output = 12x12xlayer_depth['layer_1'].\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 8x8xlayer_depth['layer_2'].\n",
    "    conv2   = tf.nn.conv2d(conv1, weights['layer_2'], strides=[1, 1, 1, 1], padding='VALID') + biases['layer_2']\n",
    "    print('conv2 has shape=',conv2.shape)\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 8x8xlayer_depth['layer_2']. Output = 4x4xlayer_depth['layer_2'].\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 4x4xlayer_depth['layer_2']. Output = 4x4xlayer_depth['layer_2'].\n",
    "    print('flatten(conv2) has shape=',flatten(conv2).shape)\n",
    "    #print('flatten(conv1) has shape=',tf.shape(flatten(conv1)))\n",
    "    #fc0   = tf.concat(1,[flatten(conv2), flatten(conv1)])\n",
    "    fc0 = flatten(conv2)\n",
    "\n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 5x5xlayer_depth['layer_2']. Output = layer_depth['fully_connected_1'].\n",
    "    fc1   = tf.matmul(fc0, weights['fully_connected_1']) + biases['fully_connected_1']\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)    # dropout\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = layer_depth['fully_connected_1']. Output = layer_depth['fully_connected_2'].\n",
    "    fc2    = tf.matmul(fc1, weights['fully_connected_2']) + biases['fully_connected_2']\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)    # dropout\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = layer_depth['fully_connected_2']. Output = layer_depth['out'].\n",
    "    logits = tf.matmul(fc2, weights['out']) + biases['out']\n",
    "    print('logits has shape=',logits.shape)\n",
    "    return logits\n",
    "\n",
    "logits = CNNMNIST_teacher(x_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('student'):\n",
    "    weights_student = {\n",
    "        'permutation': tf.get_variable('permutation',shape=(img_height,img_width),trainable=True),\n",
    "        'layer_1': tf.get_variable('layer_1w', shape=(kSize, kSize, cNum, layer_depth['layer_1']), initializer=tf.random_normal_initializer(mu,sigma), trainable=False),\n",
    "        'layer_2': tf.get_variable('layer_2w', shape=(kSize, kSize, layer_depth['layer_1'], layer_depth['layer_2']), initializer=tf.random_normal_initializer(mu,sigma), trainable=False),\n",
    "        'fully_connected_1': tf.get_variable('fully_connected_1w', shape=(4*4*layer_depth['layer_2'], layer_depth['fully_connected_1']), initializer=tf.random_normal_initializer(mu,sigma), trainable=False),\n",
    "        'fully_connected_2': tf.get_variable('fully_connected_2w', shape=(layer_depth['fully_connected_1'], layer_depth['fully_connected_2']), initializer=tf.random_normal_initializer(mu,sigma), trainable=False),\n",
    "        'out': tf.get_variable('outw', shape=(layer_depth['fully_connected_2'], layer_depth['out']), initializer=tf.random_normal_initializer(mu,sigma), trainable=False)\n",
    "    }\n",
    "    #+0.3 over the first epochs than +-0\n",
    "\n",
    "    biases_student = {\n",
    "        'layer_1': tf.get_variable('layer_1b', shape=(layer_depth['layer_1']),\\\n",
    "                                   initializer=tf.zeros_initializer, trainable=False),\n",
    "        'layer_2': tf.get_variable('layer_2b', shape=(layer_depth['layer_2']),\\\n",
    "                                   initializer=tf.zeros_initializer, trainable=False),\n",
    "        'fully_connected_1': tf.get_variable('fully_connected_1b', shape=(layer_depth['fully_connected_1']),\\\n",
    "                                             initializer=tf.zeros_initializer, trainable=False),\n",
    "        'fully_connected_2': tf.get_variable('fully_connected_2b', shape=(layer_depth['fully_connected_2']),\\\n",
    "                                             initializer=tf.zeros_initializer, trainable=False),\n",
    "        'out': tf.get_variable('outb', shape=(layer_depth['out']),initializer=tf.zeros_initializer, trainable=False)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Scope: len(trainable_collection_t)=10; len(global_collection_t)=10\n",
      "Without Scope: len(trainable_collection_s)=1; len(global_collection_s)=11\n",
      "Without Scope: len(trainable_collection)=11; len(global_collection)=21\n"
     ]
    }
   ],
   "source": [
    "trainable_collection_t = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='teacher')\n",
    "global_collection_t = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='teacher')\n",
    "print('Without Scope: len(trainable_collection_t)={}; len(global_collection_t)={}'.format(len(trainable_collection_t),len(global_collection_t)))\n",
    "\n",
    "trainable_collection_s = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='student')\n",
    "global_collection_s = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='student')\n",
    "print('Without Scope: len(trainable_collection_s)={}; len(global_collection_s)={}'.format(len(trainable_collection_s),len(global_collection_s)))\n",
    "\n",
    "trainable_collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "global_collection = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "print('Without Scope: len(trainable_collection)={}; len(global_collection)={}'.format(len(trainable_collection),len(global_collection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'teacher/layer_1w:0' shape=(5, 5, 1, 16) dtype=float32_ref>, <tf.Variable 'teacher/layer_2w:0' shape=(5, 5, 16, 32) dtype=float32_ref>, <tf.Variable 'teacher/fully_connected_1w:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'teacher/fully_connected_2w:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'teacher/outw:0' shape=(128, 2) dtype=float32_ref>, <tf.Variable 'teacher/layer_1b:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'teacher/layer_2b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'teacher/fully_connected_1b:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'teacher/fully_connected_2b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'teacher/outb:0' shape=(2,) dtype=float32_ref>]\n",
      "\n",
      "\n",
      "[<tf.Variable 'student/permutation:0' shape=(28, 28) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(trainable_collection_t)\n",
    "print('\\n')\n",
    "print(trainable_collection_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28)\n",
      "conv1 has shape= (?, 24, 24, 16)\n",
      "conv2 has shape= (?, 8, 8, 32)\n",
      "flatten(conv2) has shape= (?, 512)\n",
      "logits has shape= (?, 2)\n"
     ]
    }
   ],
   "source": [
    "def CNNMNIST_student(x):\n",
    "    bsize = tf.shape(x)[0]\n",
    "    # processing the permutation matrix\n",
    "    #x = tf.squeeze(x) # (batch_sizex28x28)\n",
    "    x = tf.reshape(x,shape=(bsize,img_height,img_width))\n",
    "    permutation = tf.tile(tf.expand_dims(weights_student['permutation'],0),[bsize,1,1])\n",
    "    print(permutation.shape)\n",
    "    x = tf.matmul(permutation,x) # (batchsizex28x28)\n",
    "    x = tf.expand_dims(x,-1) # (batchsizex28x28x1)\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 28x28xcNum. Output = 24x24xlayer_depth['layer_1'].\n",
    "    conv1   = tf.nn.conv2d(x, weights_student['layer_1'], strides=[1, 1, 1, 1], padding='VALID') + biases_student['layer_1']\n",
    "    print('conv1 has shape=',conv1.shape)\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 24x24xlayer_depth['layer_1']. Output = 12x12xlayer_depth['layer_1'].\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 8x8xlayer_depth['layer_2'].\n",
    "    conv2   = tf.nn.conv2d(conv1, weights_student['layer_2'], strides=[1, 1, 1, 1], padding='VALID') + biases_student['layer_2']\n",
    "    print('conv2 has shape=',conv2.shape)\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 8x8xlayer_depth['layer_2']. Output = 4x4xlayer_depth['layer_2'].\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 4x4xlayer_depth['layer_2']. Output = 4x4xlayer_depth['layer_2'].\n",
    "    print('flatten(conv2) has shape=',flatten(conv2).shape)\n",
    "    #print('flatten(conv1) has shape=',tf.shape(flatten(conv1)))\n",
    "    #fc0   = tf.concat(1,[flatten(conv2), flatten(conv1)])\n",
    "    fc0 = flatten(conv2)\n",
    "\n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 5x5xlayer_depth['layer_2']. Output = layer_depth['fully_connected_1'].\n",
    "    fc1   = tf.matmul(fc0, weights_student['fully_connected_1']) + biases_student['fully_connected_1']\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)    # dropout\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = layer_depth['fully_connected_1']. Output = layer_depth['fully_connected_2'].\n",
    "    fc2    = tf.matmul(fc1, weights_student['fully_connected_2']) + biases_student['fully_connected_2']\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)    # dropout\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = layer_depth['fully_connected_2']. Output = layer_depth['out'].\n",
    "    logits = tf.matmul(fc2, weights_student['out']) + biases_student['out']\n",
    "    print('logits has shape=',logits.shape)\n",
    "    return logits\n",
    "\n",
    "logits_student = CNNMNIST_student(x_feed_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss, optimizer\n",
    "# softmax_cross_entropy_with_logits: https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "# labels: Each row labels[i] must be a valid probability distribution.\n",
    "# logits: Unscaled log probabilities.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y_feed,logits=logits)\n",
    "\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "loss_tf_op = tf.nn.l2_loss(logits_student-logits)\n",
    "optimizer_tf = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_tf_operation = optimizer_tf.minimize(loss_tf_op, var_list = trainable_collection_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define accuracy evaluation\n",
    "# calculate the average accuracy by calling evaluate(X_data, y_data)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, axis=1), tf.argmax(one_hot_y_feed, axis=1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    assert(len(X_data)==len(y_data))\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x_feed: batch_x, one_hot_y_feed: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "correct_prediction_student = tf.equal(tf.argmax(logits_student, axis=1), tf.argmax(one_hot_y_feed_student, axis=1))\n",
    "accuracy_operation_student = tf.reduce_mean(tf.cast(correct_prediction_student, tf.float32))\n",
    "def evaluate_student(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    assert(len(X_data)==len(y_data))\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation_student, feed_dict={x_feed_student: batch_x, one_hot_y_feed_student: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Train Accuracy = 0.994; Flip Accuracy = 0.180\n",
      "\n",
      "EPOCH 2 ...\n",
      "Train Accuracy = 0.999; Flip Accuracy = 0.192\n",
      "\n",
      "EPOCH 3 ...\n",
      "Train Accuracy = 0.999; Flip Accuracy = 0.080\n",
      "\n",
      "Model saved\n",
      "Before assignment\n",
      "After assignment\n",
      "EPOCH 1 ...\n",
      "Acc loss = 9.52696829760659\n",
      "Train Accuracy = 0.460; Flip Accuracy = 0.806\n",
      "\n",
      "EPOCH 2 ...\n",
      "Acc loss = 3.6580730849143146\n",
      "Train Accuracy = 0.364; Flip Accuracy = 0.955\n",
      "\n",
      "EPOCH 3 ...\n",
      "Acc loss = 2.454553008463332\n",
      "Train Accuracy = 0.304; Flip Accuracy = 0.980\n",
      "\n",
      "EPOCH 4 ...\n",
      "Acc loss = 1.823352760733923\n",
      "Train Accuracy = 0.277; Flip Accuracy = 0.988\n",
      "\n",
      "EPOCH 5 ...\n",
      "Acc loss = 1.4707165408316494\n",
      "Train Accuracy = 0.235; Flip Accuracy = 0.992\n",
      "\n",
      "EPOCH 6 ...\n",
      "Acc loss = 1.213175814588861\n",
      "Train Accuracy = 0.212; Flip Accuracy = 0.994\n",
      "\n",
      "EPOCH 7 ...\n",
      "Acc loss = 1.0669785058220949\n",
      "Train Accuracy = 0.183; Flip Accuracy = 0.995\n",
      "\n",
      "EPOCH 8 ...\n",
      "Acc loss = 0.9374155159126417\n",
      "Train Accuracy = 0.192; Flip Accuracy = 0.995\n",
      "\n",
      "EPOCH 9 ...\n",
      "Acc loss = 0.8563255553587239\n",
      "Train Accuracy = 0.172; Flip Accuracy = 0.996\n",
      "\n",
      "EPOCH 10 ...\n",
      "Acc loss = 0.7726570629786244\n",
      "Train Accuracy = 0.169; Flip Accuracy = 0.996\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "### Train your model here.\n",
    "# mini-batch Adam training, will save model as ./models/mnist-cnn-model\n",
    "if not os.path.isdir('./models'):\n",
    "    os.makedirs('./models')\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = x_num\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    train_accuracy = np.zeros(EPOCHS)\n",
    "    flip_accuracy = np.zeros(EPOCHS)\n",
    "    for i in range(EPOCHS):\n",
    "        acc_train_accuracy = 0\n",
    "        X_train, y_train = shuffle(x, y1hot)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x_feed: batch_x, one_hot_y_feed: batch_y, keep_prob: drop_out_keep_prob})\n",
    "            acc_train_accuracy += evaluate(batch_x, batch_y)\n",
    "        train_accuracy[i] = acc_train_accuracy/len(range(0, num_examples, BATCH_SIZE))\n",
    "        flip_accuracy[i] = evaluate(x_flip, y1hot_flip)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        #print(\"Train Accuracy = {:.3f}\".format(train_accuracy[i]))\n",
    "        print(\"Train Accuracy = {:.3f}; Flip Accuracy = {:.3f}\".format(train_accuracy[i],flip_accuracy[i]))\n",
    "        print()\n",
    "    saver.save(sess, './models/mnist-cnn-model')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "    \"\"\"\n",
    "    We Then Do the Copy from Teacher to Student Models\n",
    "    \"\"\"\n",
    "    print('Before assignment')\n",
    "    #print(sess.run(weights_student['layer_1']))\n",
    "    sess.run(weights_student['layer_1'].assign(weights['layer_1']))\n",
    "    sess.run(weights_student['layer_2'].assign(weights['layer_2']))\n",
    "    sess.run(weights_student['fully_connected_1'].assign(weights['fully_connected_1']))\n",
    "    sess.run(weights_student['fully_connected_2'].assign(weights['fully_connected_2']))\n",
    "    sess.run(weights_student['out'].assign(weights['out']))\n",
    "    sess.run(biases_student['layer_1'].assign(biases['layer_1']))\n",
    "    sess.run(biases_student['layer_2'].assign(biases['layer_2']))\n",
    "    sess.run(biases_student['fully_connected_1'].assign(biases['fully_connected_1']))\n",
    "    sess.run(biases_student['fully_connected_2'].assign(biases['fully_connected_2']))\n",
    "    sess.run(biases_student['out'].assign(biases['out']))\n",
    "    print('After assignment')\n",
    "    #print(sess.run(weights_student['layer_1']))\n",
    "    \n",
    "    \"\"\"\n",
    "    Using Flipped Images to Unsupervised Training the Original Net\n",
    "    \"\"\"\n",
    "    train_accuracy_tf = np.zeros(EPOCHS_TF)\n",
    "    flip_accuracy_tf = np.zeros(EPOCHS_TF)\n",
    "    for i in range(EPOCHS_TF):\n",
    "        acc_loss = 0.0\n",
    "        X_train, X_train_flip = shuffle(x_rest, x_rest_flip)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x = X_train[offset:end]\n",
    "            batch_x_flip = X_train_flip[offset:end]\n",
    "            _, l = sess.run([training_tf_operation, loss_tf_op], feed_dict={x_feed: batch_x,\\\n",
    "                                                                            x_feed_student: batch_x_flip,\\\n",
    "                                                                            keep_prob: 1.0})\n",
    "            #print('Current loss in batch = {}'.format(l))\n",
    "            acc_loss += l\n",
    "        acc_loss /= num_examples\n",
    "        #train_accuracy_tf[i] = evaluate(x, y1hot)\n",
    "        train_accuracy_tf[i] = evaluate_student(x, y1hot)\n",
    "        flip_accuracy_tf[i] = evaluate_student(x_flip, y1hot_flip)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Acc loss = {}\".format(acc_loss))\n",
    "        print(\"Train Accuracy = {:.3f}; Flip Accuracy = {:.3f}\".format(train_accuracy_tf[i],flip_accuracy_tf[i]))\n",
    "        print()\n",
    "    saver.save(sess, './models_tf/mnist-cnn-model')\n",
    "    print(\"Model saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We then checkout the permutation matrix !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models_tf/mnist-cnn-model\n",
      "[[-0.33652213  0.194096    0.01185159 -0.21441045 -0.05837967 -0.30272174\n",
      "   0.25788119  0.17097554  0.2315713  -0.0270125  -0.34895688  0.02194827\n",
      "  -0.04041349  0.06443283  0.20175146 -0.02515851 -0.28603825  0.06758212\n",
      "   0.04779549  0.1780389  -0.2071728   0.12291357 -0.235321   -0.23071177\n",
      "  -0.16024549  0.40447283 -0.11055614  0.00674399]\n",
      " [-0.2381878  -0.37216341  0.12914696 -0.06254674 -0.14244145  0.20884068\n",
      "  -0.05568084 -0.27007377 -0.11992516 -0.37534025 -0.48011515 -0.34975278\n",
      "  -0.11220517 -0.32637328  0.18099456  0.04144622 -0.07538597 -0.01104459\n",
      "  -0.05615342  0.17611469  0.11019797 -0.00876631 -0.01782795  0.23411065\n",
      "   0.05650008  0.30270171 -0.01349568 -0.22177105]\n",
      " [ 0.09385606  0.05471779  0.00948903  0.02050059  0.19180992  0.13648649\n",
      "   0.11957303  0.30843458 -0.13916585  0.18250479 -0.1021389   0.1333264\n",
      "  -0.1912207   0.10002661  0.19139905  0.07210119  0.32196593  0.05936131\n",
      "   0.29458749  0.09342391 -0.05581735 -0.3189725  -0.12010004 -0.02504512\n",
      "   0.27171296 -0.12961861 -0.23893179 -0.09541804]\n",
      " [ 0.09984867 -0.13141651  0.08735589 -0.04185273 -0.103034    0.09175996\n",
      "   0.15405224  0.13566591 -0.07708732  0.02777727  0.01941134 -0.07180368\n",
      "  -0.20201708  0.28784081  0.0199862   0.06197742  0.10081413  0.00544378\n",
      "  -0.19800326 -0.09194056 -0.33320296  0.04300705 -0.10805611 -0.11895876\n",
      "  -0.13415524  0.03107841 -0.01254334 -0.06437059]\n",
      " [ 0.10058435  0.07531837 -0.33462515 -0.05702595 -0.2740646   0.08421337\n",
      "   0.0173758  -0.09348214  0.20443298  0.18340667  0.18278019  0.06137875\n",
      "   0.40523151 -0.06420832 -0.07778205  0.10759255 -0.27024347  0.2344583\n",
      "  -0.04794658  0.36762816 -0.06424683  0.13474767  0.28184918  0.19677845\n",
      "  -0.47112268 -0.15688637  0.1597676   0.22311138]\n",
      " [ 0.08613499 -0.23587444 -0.21551359  0.24791424 -0.06961068  0.20686026\n",
      "  -0.01419163  0.15930815  0.11795856  0.29028782  0.0252643   0.04078962\n",
      "   0.39039195  0.06781688 -0.0708276  -0.14025758 -0.36395764  0.11234453\n",
      "  -0.19925772  0.17191406  0.37470499  0.33875176  0.11032606  0.13586669\n",
      "   0.14286795 -0.40443033 -0.26954186 -0.19980583]\n",
      " [ 0.25201741  0.35947415  0.31961346  0.04715062  0.20458119  0.05673128\n",
      "  -0.23437382  0.09356159 -0.25848922  0.20181204 -0.16675512 -0.14936696\n",
      "   0.23891208  0.19351488 -0.11466051 -0.19125734  0.29292211 -0.04957277\n",
      "   0.19273934  0.3552978   0.19618307 -0.17635833  0.0303796   0.15618628\n",
      "   0.11229017 -0.07412074 -0.35102537 -0.14252438]\n",
      " [-0.26375663  0.37651584  0.2238204   0.30110571 -0.07963965 -0.16038606\n",
      "   0.05675856  0.21507956  0.21149032 -0.18052059  0.28670797 -0.09454554\n",
      "  -0.02374486 -0.00937493  0.14056921  0.02453124 -0.0427205   0.07603659\n",
      "   0.16443424 -0.08946939  0.16788432  0.02394644  0.21793668 -0.02103641\n",
      "  -0.32758284 -0.44951269 -0.31713668 -0.07227556]\n",
      " [ 0.19415095  0.37086833  0.21122085 -0.06984953  0.35023922  0.28639007\n",
      "  -0.26959968  0.15268466  0.2968705  -0.16391452 -0.21500483  0.0323206\n",
      "   0.0907532  -0.12505707  0.26706141  0.26415372 -0.22056261  0.03288109\n",
      "   0.22513177  0.06766862 -0.03042785  0.41313311  0.01980633 -0.25190496\n",
      "  -0.37242401  0.03136738 -0.38887724  0.243617  ]\n",
      " [ 0.299059    0.01026583  0.23011468  0.26697847 -0.21691363  0.03039114\n",
      "  -0.30235937  0.08563904 -0.0228832  -0.20693193  0.19263186 -0.02229157\n",
      "  -0.21026972  0.35622883  0.23439452  0.38869089 -0.02343747  0.2477639\n",
      "  -0.18416245  0.38943753  0.23103321  0.02011617 -0.11423559 -0.01696904\n",
      "  -0.07212111 -0.46498257 -0.00265269 -0.28123471]\n",
      " [-0.04920229  0.17227691  0.07834212  0.22559367 -0.27977765  0.22344765\n",
      "   0.18651767  0.18875898 -0.33606401 -0.24278022  0.21728961  0.07136281\n",
      "  -0.08647087 -0.12559684  0.06528937  0.21567155  0.13108431 -0.00814432\n",
      "   0.34513009 -0.01502603 -0.23143436  0.0679284   0.09650312 -0.07403196\n",
      "   0.0560725   0.0966263  -0.18777534 -0.25792494]\n",
      " [ 0.28593045  0.31875107 -0.04141669 -0.10191002 -0.11575551 -0.03889444\n",
      "  -0.06116547 -0.34697998  0.25355831  0.1661687  -0.2076828   0.02550209\n",
      "  -0.05392038  0.23942438  0.19743405 -0.06854782  0.23205273  0.39987355\n",
      "   0.17608422  0.21398084  0.31627527 -0.14910489 -0.41006425  0.00566313\n",
      "  -0.25141034  0.20512943  0.07944954 -0.03009982]\n",
      " [ 0.01868769  0.05487648  0.02875104 -0.11529679  0.28187123 -0.18037724\n",
      "   0.12568267  0.14598666 -0.11112443  0.17163543 -0.12370377  0.02547057\n",
      "  -0.02453161  0.00089492  0.19304925  0.28641868  0.39370099  0.36571679\n",
      "   0.30137479  0.11899483 -0.27078125 -0.29760456  0.21523467 -0.09474404\n",
      "   0.00824733  0.05606299  0.1758707  -0.08831459]\n",
      " [ 0.09378754  0.21593739 -0.34035665 -0.11203502  0.17591003 -0.19699398\n",
      "   0.22752517  0.1476166  -0.25687876  0.13425975 -0.02175862  0.05314079\n",
      "  -0.09686098  0.47501874  0.57223099  0.21046454  0.44717443 -0.03371333\n",
      "  -0.46278918 -0.22069019 -0.09688004  0.00447289 -0.09137837  0.11949065\n",
      "  -0.40127221  0.20602287 -0.35906181  0.07020085]\n",
      " [-0.24809641  0.21077114  0.23402807  0.10528219 -0.05510721 -0.24722727\n",
      "   0.0066506   0.13515435  0.06678903  0.37805551 -0.06124824  0.0126778\n",
      "   0.58534032  0.05847328  0.05060964 -0.07877266  0.12167133 -0.39624995\n",
      "  -0.16779672  0.13254204  0.07721636  0.02516119 -0.09057741  0.02794082\n",
      "   0.11098034 -0.02666997 -0.02564803 -0.27798104]\n",
      " [-0.36140639 -0.28850245 -0.10733864 -0.38918254 -0.08721346  0.08757902\n",
      "   0.0217239  -0.09837724 -0.01675101 -0.17863858  0.07342396  0.18675846\n",
      "   0.12524149  0.21121551  0.27222717  0.24092703  0.25963333 -0.06844559\n",
      "   0.07535128  0.04687379  0.05332465  0.02881662 -0.25487763 -0.19387604\n",
      "  -0.103095    0.10537422  0.2658605  -0.25684115]\n",
      " [ 0.18778406 -0.23137332 -0.3357822  -0.19032839  0.2149372  -0.14719653\n",
      "   0.23643979 -0.21058428  0.11874332  0.13703915  0.33590442  0.31722546\n",
      "   0.23433304  0.29838324  0.11376012 -0.36511055  0.08269305  0.25182334\n",
      "  -0.29935837 -0.12586962  0.02485932 -0.07088615  0.04831291 -0.1061129\n",
      "   0.13827063 -0.0743298  -0.10223877  0.08283372]\n",
      " [ 0.18633097 -0.15660401 -0.11920844 -0.22350681  0.19215994 -0.18937702\n",
      "  -0.11238904  0.3928861   0.467343    0.37578562  0.01843411  0.36461198\n",
      "   0.18966062 -0.04150046  0.1228985  -0.0171268  -0.12628908  0.01788913\n",
      "   0.08922351  0.25859797 -0.17288736 -0.20465578 -0.24505423  0.13368985\n",
      "   0.23162311  0.41715288 -0.27052    -0.310002  ]\n",
      " [ 0.13792193 -0.01148199  0.01279816 -0.09841517 -0.14425337 -0.04528984\n",
      "  -0.01293034  0.5192883   0.24513349  0.29391962 -0.02466552  0.00898885\n",
      "   0.08092584 -0.2957063   0.10854848  0.19855243 -0.11738602  0.08148991\n",
      "   0.06985263 -0.28649393  0.06676377  0.03352157  0.02955627  0.14244622\n",
      "  -0.02764337 -0.11304959  0.29587647 -0.22557683]\n",
      " [-0.08006846  0.15221766 -0.18627429  0.13734007  0.03332895  0.24679309\n",
      "  -0.04205936  0.21909913 -0.02397902  0.25595409  0.32425997 -0.23433113\n",
      "   0.24035802  0.0811785  -0.17295213  0.0638117   0.1624472  -0.25694793\n",
      "  -0.08982003  0.18000685  0.19642644  0.11792928  0.29509315 -0.12017626\n",
      "  -0.09088127 -0.12482954  0.34017923 -0.03564408]\n",
      " [-0.25962311 -0.01971685 -0.24867652 -0.04481763  0.144657   -0.1904646\n",
      "  -0.1220096   0.23577529  0.05516502  0.25686333 -0.00892391 -0.23553821\n",
      "  -0.10188633 -0.10488308 -0.01271864  0.09003294  0.01227234 -0.16003986\n",
      "   0.12983434 -0.27659231 -0.15812533  0.22106034 -0.23039053  0.30253318\n",
      "   0.36995676 -0.04011698 -0.24399573  0.09204721]\n",
      " [ 0.03980458 -0.26456398 -0.25435162 -0.31066889 -0.1257055  -0.14799102\n",
      "   0.24848692  0.19806486 -0.02841545  0.05315506  0.28178769  0.09280907\n",
      "   0.22072116  0.17537533 -0.02488175  0.03386356  0.09327522  0.03935827\n",
      "   0.22137523 -0.02594414  0.0810237  -0.19318165  0.1193288  -0.0906546\n",
      "  -0.08444797 -0.11874712  0.33387759 -0.12532288]\n",
      " [-0.22556934  0.03251863 -0.14735176 -0.15716271 -0.10320079  0.25289357\n",
      "   0.41754219  0.13870327  0.43757871  0.08287089 -0.06329525 -0.01204087\n",
      "   0.09039824 -0.16695233  0.28003871  0.21664184  0.11945265  0.06688741\n",
      "  -0.1353837   0.01836987 -0.2851308   0.15692708  0.12496115  0.27892756\n",
      "   0.27444854  0.05667756  0.00895084  0.24598569]\n",
      " [ 0.19028859 -0.43451965 -0.0712598  -0.16026841 -0.07513541 -0.16188124\n",
      "  -0.17933638 -0.2657432   0.00841049 -0.23351985  0.13264756  0.14611579\n",
      "   0.07477155  0.19130582 -0.19114085  0.10789686 -0.05319874 -0.09793024\n",
      "   0.092564    0.04277151  0.11851802 -0.02887163 -0.16380438 -0.04233296\n",
      "  -0.26694337 -0.44714743 -0.09972458 -0.14758095]\n",
      " [-0.0982508  -0.13794659 -0.18056165  0.1713143  -0.0989069  -0.25833815\n",
      "  -0.02194241 -0.02354653  0.04771763  0.05547079 -0.11276224  0.28332123\n",
      "   0.13741241  0.11921538  0.23947538  0.18897769 -0.02516574  0.06418058\n",
      "  -0.22799069  0.22474198  0.42039421 -0.03452801 -0.12044574 -0.41295445\n",
      "  -0.02579881 -0.48006088 -0.04152586 -0.16405277]\n",
      " [-0.15383779 -0.16335094  0.19872265  0.37913758  0.10423321  0.06194923\n",
      "   0.21258605  0.01715287  0.05589089 -0.0309934  -0.20353703  0.15413551\n",
      "   0.23235366 -0.24505131  0.18095735 -0.19606359 -0.15907943  0.27557382\n",
      "   0.32023162 -0.18531184  0.29955098 -0.01778328  0.0762257  -0.31021807\n",
      "  -0.18659683 -0.07072543 -0.19187574  0.01107778]\n",
      " [ 0.23657759 -0.04722283 -0.34618849 -0.19292152 -0.34366861 -0.12184989\n",
      "  -0.07316651 -0.38000235 -0.02334767  0.03024284  0.37797043  0.02741911\n",
      "   0.14582536  0.24400936 -0.41338634 -0.17193173 -0.0913789   0.05775322\n",
      "   0.41761345  0.20779842 -0.06745455  0.12602729 -0.01690535  0.10137211\n",
      "  -0.37265596  0.12719423  0.24325211 -0.1490726 ]\n",
      " [ 0.01449487  0.39507967  0.47439015  0.18680377  0.14496316  0.17482494\n",
      "   0.34874049  0.19707072  0.10447621  0.37593231  0.14625278  0.4158603\n",
      "  -0.137586    0.31071118  0.24646547 -0.04007516  0.04895582 -0.00851532\n",
      "   0.30531102  0.55077606  0.22966824  0.37471223 -0.12174805  0.15889275\n",
      "  -0.35109368 -0.26274616 -0.18812564 -0.19203544]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./models_tf'))\n",
    "    print(sess.run(weights_student['permutation']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
